{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('../../datasets/zhengqi/zhengqi_train.txt')\n",
    "test_data = pd.read_table('../../datasets/zhengqi/zhengqi_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>-0.067790</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>-0.558565</td>\n",
       "      <td>0.182892</td>\n",
       "      <td>0.116155</td>\n",
       "      <td>0.177856</td>\n",
       "      <td>-0.169452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097648</td>\n",
       "      <td>0.055477</td>\n",
       "      <td>0.127791</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.197764</td>\n",
       "      <td>0.030658</td>\n",
       "      <td>-0.130330</td>\n",
       "      <td>0.126353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.928031</td>\n",
       "      <td>0.941515</td>\n",
       "      <td>0.911236</td>\n",
       "      <td>0.970298</td>\n",
       "      <td>0.888377</td>\n",
       "      <td>0.517957</td>\n",
       "      <td>0.918054</td>\n",
       "      <td>0.955116</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.953813</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061200</td>\n",
       "      <td>0.901934</td>\n",
       "      <td>0.873028</td>\n",
       "      <td>0.902584</td>\n",
       "      <td>1.006995</td>\n",
       "      <td>1.003291</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>0.970812</td>\n",
       "      <td>1.017196</td>\n",
       "      <td>0.983966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.335000</td>\n",
       "      <td>-5.122000</td>\n",
       "      <td>-3.420000</td>\n",
       "      <td>-3.956000</td>\n",
       "      <td>-4.742000</td>\n",
       "      <td>-2.182000</td>\n",
       "      <td>-4.576000</td>\n",
       "      <td>-5.048000</td>\n",
       "      <td>-4.692000</td>\n",
       "      <td>-12.891000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.912000</td>\n",
       "      <td>-4.507000</td>\n",
       "      <td>-5.859000</td>\n",
       "      <td>-4.053000</td>\n",
       "      <td>-4.627000</td>\n",
       "      <td>-4.789000</td>\n",
       "      <td>-5.695000</td>\n",
       "      <td>-2.608000</td>\n",
       "      <td>-3.630000</td>\n",
       "      <td>-3.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.297000</td>\n",
       "      <td>-0.226250</td>\n",
       "      <td>-0.313000</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-0.385000</td>\n",
       "      <td>-0.853000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.295000</td>\n",
       "      <td>-0.159000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664000</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>-0.170250</td>\n",
       "      <td>-0.407250</td>\n",
       "      <td>-0.499000</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.202500</td>\n",
       "      <td>-0.413000</td>\n",
       "      <td>-0.798250</td>\n",
       "      <td>-0.350250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>-0.044500</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>-0.466000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>-0.185500</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.918250</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.550250</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745250</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.644250</td>\n",
       "      <td>0.495250</td>\n",
       "      <td>0.793250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.121000</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>2.457000</td>\n",
       "      <td>2.689000</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>1.895000</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>1.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.580000</td>\n",
       "      <td>2.689000</td>\n",
       "      <td>2.013000</td>\n",
       "      <td>2.395000</td>\n",
       "      <td>5.465000</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>2.324000</td>\n",
       "      <td>5.238000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.538000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V0           V1           V2           V3           V4  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.123048     0.056068     0.289720    -0.067790     0.012921   \n",
       "std       0.928031     0.941515     0.911236     0.970298     0.888377   \n",
       "min      -4.335000    -5.122000    -3.420000    -3.956000    -4.742000   \n",
       "25%      -0.297000    -0.226250    -0.313000    -0.652250    -0.385000   \n",
       "50%       0.359000     0.272500     0.386000    -0.044500     0.110000   \n",
       "75%       0.726000     0.599000     0.918250     0.624000     0.550250   \n",
       "max       2.121000     1.918000     2.828000     2.457000     2.689000   \n",
       "\n",
       "                V5           V6           V7           V8           V9  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean     -0.558565     0.182892     0.116155     0.177856    -0.169452   \n",
       "std       0.517957     0.918054     0.955116     0.895444     0.953813   \n",
       "min      -2.182000    -4.576000    -5.048000    -4.692000   -12.891000   \n",
       "25%      -0.853000    -0.310000    -0.295000    -0.159000    -0.390000   \n",
       "50%      -0.466000     0.388000     0.344000     0.362000     0.042000   \n",
       "75%      -0.154000     0.831250     0.782250     0.726000     0.042000   \n",
       "max       0.489000     1.895000     1.918000     2.245000     1.335000   \n",
       "\n",
       "          ...               V29          V30          V31          V32  \\\n",
       "count     ...       2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      ...          0.097648     0.055477     0.127791     0.020806   \n",
       "std       ...          1.061200     0.901934     0.873028     0.902584   \n",
       "min       ...         -2.912000    -4.507000    -5.859000    -4.053000   \n",
       "25%       ...         -0.664000    -0.283000    -0.170250    -0.407250   \n",
       "50%       ...         -0.023000     0.053500     0.299500     0.039000   \n",
       "75%       ...          0.745250     0.488000     0.635000     0.557000   \n",
       "max       ...          4.580000     2.689000     2.013000     2.395000   \n",
       "\n",
       "               V33          V34          V35          V36          V37  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.007801     0.006715     0.197764     0.030658    -0.130330   \n",
       "std       1.006995     1.003291     0.985675     0.970812     1.017196   \n",
       "min      -4.627000    -4.789000    -5.695000    -2.608000    -3.630000   \n",
       "25%      -0.499000    -0.290000    -0.202500    -0.413000    -0.798250   \n",
       "50%      -0.040000     0.160000     0.364000     0.137000    -0.185500   \n",
       "75%       0.462000     0.273000     0.602000     0.644250     0.495250   \n",
       "max       5.465000     5.110000     2.324000     5.238000     3.000000   \n",
       "\n",
       "            target  \n",
       "count  2888.000000  \n",
       "mean      0.126353  \n",
       "std       0.983966  \n",
       "min      -3.044000  \n",
       "25%      -0.350250  \n",
       "50%       0.313000  \n",
       "75%       0.793250  \n",
       "max       2.538000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['target'].values\n",
    "X_train = train_data.drop('target', axis=1).values\n",
    "X_test = test_data.values\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.962224\tvalid_data-rmse:0.981312\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.213893\tvalid_data-rmse:0.332196\n",
      "[200]\ttrain-rmse:0.153767\tvalid_data-rmse:0.327006\n",
      "[300]\ttrain-rmse:0.114048\tvalid_data-rmse:0.325163\n",
      "[400]\ttrain-rmse:0.088236\tvalid_data-rmse:0.321667\n",
      "[500]\ttrain-rmse:0.068231\tvalid_data-rmse:0.320212\n",
      "[600]\ttrain-rmse:0.053331\tvalid_data-rmse:0.320307\n",
      "[700]\ttrain-rmse:0.041446\tvalid_data-rmse:0.320105\n",
      "[800]\ttrain-rmse:0.03242\tvalid_data-rmse:0.319863\n",
      "[900]\ttrain-rmse:0.025701\tvalid_data-rmse:0.320174\n",
      "[1000]\ttrain-rmse:0.02062\tvalid_data-rmse:0.320053\n",
      "Stopping. Best iteration:\n",
      "[810]\ttrain-rmse:0.031623\tvalid_data-rmse:0.319828\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.977985\tvalid_data-rmse:0.904619\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.214043\tvalid_data-rmse:0.367799\n",
      "[200]\ttrain-rmse:0.151188\tvalid_data-rmse:0.359096\n",
      "[300]\ttrain-rmse:0.111542\tvalid_data-rmse:0.356734\n",
      "[400]\ttrain-rmse:0.08584\tvalid_data-rmse:0.35514\n",
      "[500]\ttrain-rmse:0.065221\tvalid_data-rmse:0.352811\n",
      "[600]\ttrain-rmse:0.050296\tvalid_data-rmse:0.352788\n",
      "[700]\ttrain-rmse:0.038825\tvalid_data-rmse:0.353005\n",
      "Stopping. Best iteration:\n",
      "[535]\ttrain-rmse:0.059283\tvalid_data-rmse:0.352294\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.966479\tvalid_data-rmse:0.960076\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.220232\tvalid_data-rmse:0.317193\n",
      "[200]\ttrain-rmse:0.157223\tvalid_data-rmse:0.309368\n",
      "[300]\ttrain-rmse:0.117585\tvalid_data-rmse:0.308709\n",
      "[400]\ttrain-rmse:0.089169\tvalid_data-rmse:0.309489\n",
      "[500]\ttrain-rmse:0.068891\tvalid_data-rmse:0.309298\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-rmse:0.112734\tvalid_data-rmse:0.307572\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.951128\tvalid_data-rmse:1.02801\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.224572\tvalid_data-rmse:0.334949\n",
      "[200]\ttrain-rmse:0.160601\tvalid_data-rmse:0.328783\n",
      "[300]\ttrain-rmse:0.11765\tvalid_data-rmse:0.327949\n",
      "[400]\ttrain-rmse:0.090292\tvalid_data-rmse:0.328068\n",
      "[500]\ttrain-rmse:0.069819\tvalid_data-rmse:0.328321\n",
      "Stopping. Best iteration:\n",
      "[305]\ttrain-rmse:0.11593\tvalid_data-rmse:0.327526\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.968212\tvalid_data-rmse:0.959088\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.215863\tvalid_data-rmse:0.321976\n",
      "[200]\ttrain-rmse:0.157336\tvalid_data-rmse:0.318287\n",
      "[300]\ttrain-rmse:0.11733\tvalid_data-rmse:0.313786\n",
      "[400]\ttrain-rmse:0.087564\tvalid_data-rmse:0.311765\n",
      "[500]\ttrain-rmse:0.066406\tvalid_data-rmse:0.311358\n",
      "[600]\ttrain-rmse:0.051297\tvalid_data-rmse:0.311473\n",
      "[700]\ttrain-rmse:0.039999\tvalid_data-rmse:0.310691\n",
      "[800]\ttrain-rmse:0.031466\tvalid_data-rmse:0.310785\n",
      "[900]\ttrain-rmse:0.024852\tvalid_data-rmse:0.310763\n",
      "Stopping. Best iteration:\n",
      "[742]\ttrain-rmse:0.036307\tvalid_data-rmse:0.310263\n",
      "\n",
      "CV score: 0.10490974\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'eta': 0.1, 'max_depth': 4, 'subsample': 0.6, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 16}\n",
    "\n",
    "# reg:linear 线性回归；reg:logistic 逻辑回归\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb = np.zeros(len(train_data))\n",
    "predictions_xgb = np.zeros(len(test_data))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°0.10888544804801513\n",
      "fold n°2\n",
      "fold n°0.13954093483790903\n",
      "fold n°3\n",
      "fold n°0.0943499326025632\n",
      "fold n°4\n",
      "fold n°0.11501970468666108\n",
      "fold n°5\n",
      "fold n°0.10329170773049902\n",
      "CV score: 0.11221967\n"
     ]
    }
   ],
   "source": [
    "##### ridge\n",
    "reg = Ridge(alpha = .5)\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_reg = np.zeros(len(train_data))\n",
    "predictions_reg = np.zeros(len(test_data))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "\n",
    "    clf = reg.fit(X_train[trn_idx], y_train[trn_idx])\n",
    "    oof_reg[val_idx] = clf.predict(X_train[val_idx])\n",
    "    print(\"fold n°{}\".format(mean_squared_error(oof_reg[val_idx], y_train[val_idx])))\n",
    "    predictions_reg += clf.predict(X_test) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_reg, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(predictions_reg)\n",
    "series.to_csv('../../datasets/zhengqi/submit.txt', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
