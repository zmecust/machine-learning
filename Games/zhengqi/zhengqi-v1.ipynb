{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_table('../../datasets/zhengqi/zhengqi_train.txt')\n",
    "test_data = pd.read_table('../../datasets/zhengqi/zhengqi_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>-0.067790</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>-0.558565</td>\n",
       "      <td>0.182892</td>\n",
       "      <td>0.116155</td>\n",
       "      <td>0.177856</td>\n",
       "      <td>-0.169452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097648</td>\n",
       "      <td>0.055477</td>\n",
       "      <td>0.127791</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.197764</td>\n",
       "      <td>0.030658</td>\n",
       "      <td>-0.130330</td>\n",
       "      <td>0.126353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.928031</td>\n",
       "      <td>0.941515</td>\n",
       "      <td>0.911236</td>\n",
       "      <td>0.970298</td>\n",
       "      <td>0.888377</td>\n",
       "      <td>0.517957</td>\n",
       "      <td>0.918054</td>\n",
       "      <td>0.955116</td>\n",
       "      <td>0.895444</td>\n",
       "      <td>0.953813</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061200</td>\n",
       "      <td>0.901934</td>\n",
       "      <td>0.873028</td>\n",
       "      <td>0.902584</td>\n",
       "      <td>1.006995</td>\n",
       "      <td>1.003291</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>0.970812</td>\n",
       "      <td>1.017196</td>\n",
       "      <td>0.983966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.335000</td>\n",
       "      <td>-5.122000</td>\n",
       "      <td>-3.420000</td>\n",
       "      <td>-3.956000</td>\n",
       "      <td>-4.742000</td>\n",
       "      <td>-2.182000</td>\n",
       "      <td>-4.576000</td>\n",
       "      <td>-5.048000</td>\n",
       "      <td>-4.692000</td>\n",
       "      <td>-12.891000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.912000</td>\n",
       "      <td>-4.507000</td>\n",
       "      <td>-5.859000</td>\n",
       "      <td>-4.053000</td>\n",
       "      <td>-4.627000</td>\n",
       "      <td>-4.789000</td>\n",
       "      <td>-5.695000</td>\n",
       "      <td>-2.608000</td>\n",
       "      <td>-3.630000</td>\n",
       "      <td>-3.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.297000</td>\n",
       "      <td>-0.226250</td>\n",
       "      <td>-0.313000</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-0.385000</td>\n",
       "      <td>-0.853000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.295000</td>\n",
       "      <td>-0.159000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664000</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>-0.170250</td>\n",
       "      <td>-0.407250</td>\n",
       "      <td>-0.499000</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.202500</td>\n",
       "      <td>-0.413000</td>\n",
       "      <td>-0.798250</td>\n",
       "      <td>-0.350250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>-0.044500</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>-0.466000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>-0.185500</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.918250</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.550250</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745250</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.644250</td>\n",
       "      <td>0.495250</td>\n",
       "      <td>0.793250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.121000</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>2.457000</td>\n",
       "      <td>2.689000</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>1.895000</td>\n",
       "      <td>1.918000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>1.335000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.580000</td>\n",
       "      <td>2.689000</td>\n",
       "      <td>2.013000</td>\n",
       "      <td>2.395000</td>\n",
       "      <td>5.465000</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>2.324000</td>\n",
       "      <td>5.238000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.538000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V0           V1           V2           V3           V4  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.123048     0.056068     0.289720    -0.067790     0.012921   \n",
       "std       0.928031     0.941515     0.911236     0.970298     0.888377   \n",
       "min      -4.335000    -5.122000    -3.420000    -3.956000    -4.742000   \n",
       "25%      -0.297000    -0.226250    -0.313000    -0.652250    -0.385000   \n",
       "50%       0.359000     0.272500     0.386000    -0.044500     0.110000   \n",
       "75%       0.726000     0.599000     0.918250     0.624000     0.550250   \n",
       "max       2.121000     1.918000     2.828000     2.457000     2.689000   \n",
       "\n",
       "                V5           V6           V7           V8           V9  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean     -0.558565     0.182892     0.116155     0.177856    -0.169452   \n",
       "std       0.517957     0.918054     0.955116     0.895444     0.953813   \n",
       "min      -2.182000    -4.576000    -5.048000    -4.692000   -12.891000   \n",
       "25%      -0.853000    -0.310000    -0.295000    -0.159000    -0.390000   \n",
       "50%      -0.466000     0.388000     0.344000     0.362000     0.042000   \n",
       "75%      -0.154000     0.831250     0.782250     0.726000     0.042000   \n",
       "max       0.489000     1.895000     1.918000     2.245000     1.335000   \n",
       "\n",
       "          ...               V29          V30          V31          V32  \\\n",
       "count     ...       2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      ...          0.097648     0.055477     0.127791     0.020806   \n",
       "std       ...          1.061200     0.901934     0.873028     0.902584   \n",
       "min       ...         -2.912000    -4.507000    -5.859000    -4.053000   \n",
       "25%       ...         -0.664000    -0.283000    -0.170250    -0.407250   \n",
       "50%       ...         -0.023000     0.053500     0.299500     0.039000   \n",
       "75%       ...          0.745250     0.488000     0.635000     0.557000   \n",
       "max       ...          4.580000     2.689000     2.013000     2.395000   \n",
       "\n",
       "               V33          V34          V35          V36          V37  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.007801     0.006715     0.197764     0.030658    -0.130330   \n",
       "std       1.006995     1.003291     0.985675     0.970812     1.017196   \n",
       "min      -4.627000    -4.789000    -5.695000    -2.608000    -3.630000   \n",
       "25%      -0.499000    -0.290000    -0.202500    -0.413000    -0.798250   \n",
       "50%      -0.040000     0.160000     0.364000     0.137000    -0.185500   \n",
       "75%       0.462000     0.273000     0.602000     0.644250     0.495250   \n",
       "max       5.465000     5.110000     2.324000     5.238000     3.000000   \n",
       "\n",
       "            target  \n",
       "count  2888.000000  \n",
       "mean      0.126353  \n",
       "std       0.983966  \n",
       "min      -3.044000  \n",
       "25%      -0.350250  \n",
       "50%       0.313000  \n",
       "75%       0.793250  \n",
       "max       2.538000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data['target'].values\n",
    "X_train = train_data.drop('target', axis=1).values\n",
    "X_test = test_data.values\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "X_train\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:1.03032\tvalid_data-rmse:1.04804\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.212907\tvalid_data-rmse:0.396633\n",
      "[200]\ttrain-rmse:0.073367\tvalid_data-rmse:0.35062\n",
      "[300]\ttrain-rmse:0.037428\tvalid_data-rmse:0.345292\n",
      "[400]\ttrain-rmse:0.020981\tvalid_data-rmse:0.343765\n",
      "[500]\ttrain-rmse:0.012301\tvalid_data-rmse:0.343202\n",
      "[600]\ttrain-rmse:0.00703\tvalid_data-rmse:0.34292\n",
      "[700]\ttrain-rmse:0.004044\tvalid_data-rmse:0.342757\n",
      "[800]\ttrain-rmse:0.002402\tvalid_data-rmse:0.342697\n",
      "[900]\ttrain-rmse:0.001426\tvalid_data-rmse:0.342668\n",
      "[1000]\ttrain-rmse:0.000881\tvalid_data-rmse:0.342656\n",
      "[1100]\ttrain-rmse:0.000594\tvalid_data-rmse:0.34265\n",
      "[1200]\ttrain-rmse:0.00052\tvalid_data-rmse:0.342649\n",
      "[1300]\ttrain-rmse:0.000502\tvalid_data-rmse:0.342647\n",
      "[1400]\ttrain-rmse:0.000492\tvalid_data-rmse:0.342647\n",
      "Stopping. Best iteration:\n",
      "[1281]\ttrain-rmse:0.000503\tvalid_data-rmse:0.342647\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:1.04867\tvalid_data-rmse:0.971168\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.211002\tvalid_data-rmse:0.41458\n",
      "[200]\ttrain-rmse:0.069715\tvalid_data-rmse:0.385981\n",
      "[300]\ttrain-rmse:0.03377\tvalid_data-rmse:0.382933\n",
      "[400]\ttrain-rmse:0.018381\tvalid_data-rmse:0.381944\n",
      "[500]\ttrain-rmse:0.010579\tvalid_data-rmse:0.381549\n",
      "[600]\ttrain-rmse:0.006509\tvalid_data-rmse:0.381392\n",
      "[700]\ttrain-rmse:0.003802\tvalid_data-rmse:0.381245\n",
      "[800]\ttrain-rmse:0.002286\tvalid_data-rmse:0.381195\n",
      "[900]\ttrain-rmse:0.001373\tvalid_data-rmse:0.381181\n",
      "[1000]\ttrain-rmse:0.000866\tvalid_data-rmse:0.381163\n",
      "[1100]\ttrain-rmse:0.000573\tvalid_data-rmse:0.381159\n",
      "[1200]\ttrain-rmse:0.000516\tvalid_data-rmse:0.381158\n",
      "[1300]\ttrain-rmse:0.000498\tvalid_data-rmse:0.381158\n",
      "Stopping. Best iteration:\n",
      "[1125]\ttrain-rmse:0.000549\tvalid_data-rmse:0.381158\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:1.03453\tvalid_data-rmse:1.03131\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.213134\tvalid_data-rmse:0.383455\n",
      "[200]\ttrain-rmse:0.071469\tvalid_data-rmse:0.341498\n",
      "[300]\ttrain-rmse:0.035576\tvalid_data-rmse:0.336693\n",
      "[400]\ttrain-rmse:0.02027\tvalid_data-rmse:0.33542\n",
      "[500]\ttrain-rmse:0.011783\tvalid_data-rmse:0.334983\n",
      "[600]\ttrain-rmse:0.007174\tvalid_data-rmse:0.334761\n",
      "[700]\ttrain-rmse:0.004328\tvalid_data-rmse:0.334656\n",
      "[800]\ttrain-rmse:0.002594\tvalid_data-rmse:0.334585\n",
      "[900]\ttrain-rmse:0.00159\tvalid_data-rmse:0.334575\n",
      "[1000]\ttrain-rmse:0.000966\tvalid_data-rmse:0.334567\n",
      "[1100]\ttrain-rmse:0.000621\tvalid_data-rmse:0.334563\n",
      "[1200]\ttrain-rmse:0.00053\tvalid_data-rmse:0.334562\n",
      "[1300]\ttrain-rmse:0.000504\tvalid_data-rmse:0.334562\n",
      "Stopping. Best iteration:\n",
      "[1118]\ttrain-rmse:0.000594\tvalid_data-rmse:0.334561\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:1.01777\tvalid_data-rmse:1.09697\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.211241\tvalid_data-rmse:0.400489\n",
      "[200]\ttrain-rmse:0.072366\tvalid_data-rmse:0.349976\n",
      "[300]\ttrain-rmse:0.03639\tvalid_data-rmse:0.344293\n",
      "[400]\ttrain-rmse:0.02027\tvalid_data-rmse:0.342928\n",
      "[500]\ttrain-rmse:0.011711\tvalid_data-rmse:0.342486\n",
      "[600]\ttrain-rmse:0.00689\tvalid_data-rmse:0.342303\n",
      "[700]\ttrain-rmse:0.004036\tvalid_data-rmse:0.34221\n",
      "[800]\ttrain-rmse:0.002382\tvalid_data-rmse:0.342168\n",
      "[900]\ttrain-rmse:0.001436\tvalid_data-rmse:0.342157\n",
      "[1000]\ttrain-rmse:0.000909\tvalid_data-rmse:0.342146\n",
      "[1100]\ttrain-rmse:0.000603\tvalid_data-rmse:0.342136\n",
      "[1200]\ttrain-rmse:0.000533\tvalid_data-rmse:0.342136\n",
      "Stopping. Best iteration:\n",
      "[1071]\ttrain-rmse:0.00067\tvalid_data-rmse:0.342136\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:1.03634\tvalid_data-rmse:1.0243\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.213229\tvalid_data-rmse:0.382441\n",
      "[200]\ttrain-rmse:0.073365\tvalid_data-rmse:0.335608\n",
      "[300]\ttrain-rmse:0.037411\tvalid_data-rmse:0.329114\n",
      "[400]\ttrain-rmse:0.021101\tvalid_data-rmse:0.327687\n",
      "[500]\ttrain-rmse:0.012392\tvalid_data-rmse:0.327074\n",
      "[600]\ttrain-rmse:0.007427\tvalid_data-rmse:0.326885\n",
      "[700]\ttrain-rmse:0.004467\tvalid_data-rmse:0.326804\n",
      "[800]\ttrain-rmse:0.002662\tvalid_data-rmse:0.326735\n",
      "[900]\ttrain-rmse:0.00166\tvalid_data-rmse:0.326698\n",
      "[1000]\ttrain-rmse:0.000998\tvalid_data-rmse:0.32668\n",
      "[1100]\ttrain-rmse:0.000618\tvalid_data-rmse:0.326673\n",
      "[1200]\ttrain-rmse:0.00054\tvalid_data-rmse:0.326671\n",
      "[1300]\ttrain-rmse:0.000511\tvalid_data-rmse:0.326669\n",
      "[1400]\ttrain-rmse:0.000499\tvalid_data-rmse:0.326669\n",
      "[1500]\ttrain-rmse:0.000493\tvalid_data-rmse:0.326668\n",
      "[1600]\ttrain-rmse:0.00049\tvalid_data-rmse:0.326668\n",
      "Stopping. Best iteration:\n",
      "[1416]\ttrain-rmse:0.000496\tvalid_data-rmse:0.326668\n",
      "\n",
      "CV score: 0.11968329\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'eta': 0.02, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 16}\n",
    "\n",
    "# reg:linear 线性回归；reg:logistic 逻辑回归\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb = np.zeros(len(train_data))\n",
    "predictions_xgb = np.zeros(len(test_data))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°0.10888544804801513\n",
      "fold n°2\n",
      "fold n°0.13954093483790903\n",
      "fold n°3\n",
      "fold n°0.0943499326025632\n",
      "fold n°4\n",
      "fold n°0.11501970468666108\n",
      "fold n°5\n",
      "fold n°0.10329170773049902\n",
      "CV score: 0.11221967\n"
     ]
    }
   ],
   "source": [
    "##### ridge\n",
    "reg = Ridge(alpha = .5)\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_reg = np.zeros(len(train_data))\n",
    "predictions_reg = np.zeros(len(test_data))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "\n",
    "    clf = reg.fit(X_train[trn_idx], y_train[trn_idx])\n",
    "    oof_reg[val_idx] = clf.predict(X_train[val_idx])\n",
    "    print(\"fold n°{}\".format(mean_squared_error(oof_reg[val_idx], y_train[val_idx])))\n",
    "    predictions_reg += clf.predict(X_test) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_reg, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.116777\tvalid_1's l2: 0.160869\n",
      "[400]\ttraining's l2: 0.0506182\tvalid_1's l2: 0.121711\n",
      "[600]\ttraining's l2: 0.031426\tvalid_1's l2: 0.11517\n",
      "[800]\ttraining's l2: 0.0211446\tvalid_1's l2: 0.112382\n",
      "[1000]\ttraining's l2: 0.014749\tvalid_1's l2: 0.11096\n",
      "[1200]\ttraining's l2: 0.0104901\tvalid_1's l2: 0.11008\n",
      "[1400]\ttraining's l2: 0.00762403\tvalid_1's l2: 0.109445\n",
      "[1600]\ttraining's l2: 0.00564447\tvalid_1's l2: 0.109022\n",
      "[1800]\ttraining's l2: 0.00424934\tvalid_1's l2: 0.108665\n",
      "[2000]\ttraining's l2: 0.00323886\tvalid_1's l2: 0.108534\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's l2: 0.0034542\tvalid_1's l2: 0.108507\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.11778\tvalid_1's l2: 0.165324\n",
      "[400]\ttraining's l2: 0.0516095\tvalid_1's l2: 0.112552\n",
      "[600]\ttraining's l2: 0.0323487\tvalid_1's l2: 0.104511\n",
      "[800]\ttraining's l2: 0.0221759\tvalid_1's l2: 0.101972\n",
      "[1000]\ttraining's l2: 0.0158349\tvalid_1's l2: 0.101024\n",
      "[1200]\ttraining's l2: 0.0116649\tvalid_1's l2: 0.100787\n",
      "Early stopping, best iteration is:\n",
      "[1120]\ttraining's l2: 0.0131263\tvalid_1's l2: 0.100718\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.117231\tvalid_1's l2: 0.151625\n",
      "[400]\ttraining's l2: 0.0497573\tvalid_1's l2: 0.118691\n",
      "[600]\ttraining's l2: 0.030829\tvalid_1's l2: 0.114465\n",
      "[800]\ttraining's l2: 0.0210564\tvalid_1's l2: 0.113073\n",
      "[1000]\ttraining's l2: 0.014989\tvalid_1's l2: 0.112397\n",
      "[1200]\ttraining's l2: 0.0109728\tvalid_1's l2: 0.11194\n",
      "[1400]\ttraining's l2: 0.00825887\tvalid_1's l2: 0.11159\n",
      "Early stopping, best iteration is:\n",
      "[1437]\ttraining's l2: 0.00785474\tvalid_1's l2: 0.111507\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.115132\tvalid_1's l2: 0.18385\n",
      "[400]\ttraining's l2: 0.0504063\tvalid_1's l2: 0.122051\n",
      "[600]\ttraining's l2: 0.0316637\tvalid_1's l2: 0.111461\n",
      "[800]\ttraining's l2: 0.0216473\tvalid_1's l2: 0.108661\n",
      "[1000]\ttraining's l2: 0.0154084\tvalid_1's l2: 0.107286\n",
      "[1200]\ttraining's l2: 0.0112782\tvalid_1's l2: 0.10663\n",
      "[1400]\ttraining's l2: 0.00848958\tvalid_1's l2: 0.106177\n",
      "[1600]\ttraining's l2: 0.00654561\tvalid_1's l2: 0.106048\n",
      "[1800]\ttraining's l2: 0.0051508\tvalid_1's l2: 0.105949\n",
      "Early stopping, best iteration is:\n",
      "[1839]\ttraining's l2: 0.00493233\tvalid_1's l2: 0.105899\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.118779\tvalid_1's l2: 0.137476\n",
      "[400]\ttraining's l2: 0.0514939\tvalid_1's l2: 0.10377\n",
      "[600]\ttraining's l2: 0.032262\tvalid_1's l2: 0.100295\n",
      "[800]\ttraining's l2: 0.0218543\tvalid_1's l2: 0.099057\n",
      "[1000]\ttraining's l2: 0.0155477\tvalid_1's l2: 0.0983375\n",
      "[1200]\ttraining's l2: 0.0114611\tvalid_1's l2: 0.0977914\n",
      "[1400]\ttraining's l2: 0.00865612\tvalid_1's l2: 0.0973557\n",
      "[1600]\ttraining's l2: 0.00663803\tvalid_1's l2: 0.0969608\n",
      "[1800]\ttraining's l2: 0.00522018\tvalid_1's l2: 0.0966778\n",
      "[2000]\ttraining's l2: 0.00415773\tvalid_1's l2: 0.0964056\n",
      "[2200]\ttraining's l2: 0.00337501\tvalid_1's l2: 0.0962255\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's l2: 0.00354318\tvalid_1's l2: 0.0961979\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.115208\tvalid_1's l2: 0.178223\n",
      "[400]\ttraining's l2: 0.0495726\tvalid_1's l2: 0.126184\n",
      "[600]\ttraining's l2: 0.0307931\tvalid_1's l2: 0.117513\n",
      "[800]\ttraining's l2: 0.0209613\tvalid_1's l2: 0.114837\n",
      "[1000]\ttraining's l2: 0.0150163\tvalid_1's l2: 0.114029\n",
      "[1200]\ttraining's l2: 0.0110829\tvalid_1's l2: 0.11357\n",
      "[1400]\ttraining's l2: 0.0083914\tvalid_1's l2: 0.113313\n",
      "Early stopping, best iteration is:\n",
      "[1373]\ttraining's l2: 0.00869148\tvalid_1's l2: 0.113292\n",
      "CV score: 0.10601935\n"
     ]
    }
   ],
   "source": [
    "#  lgb\n",
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.008,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "# max_depth < 0 模型深度没限制\n",
    "\n",
    "folds = KFold(n_splits=6, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(train_data))\n",
    "predictions_lgb = np.zeros(len(test_data))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(predictions_lgb)\n",
    "series.to_csv('../../datasets/zhengqi/submit.txt', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
