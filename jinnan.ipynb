{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/jinnan/jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('datasets/jinnan/jinnan_round1_testA_20181227.csv', encoding = 'gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 删除类别唯一的特征\n",
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 删除缺失率超过90%的列\n",
    "good_cols = list(train.columns)\n",
    "for col in train.columns:\n",
    "    rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        good_cols.remove(col)\n",
    "\n",
    "# 删除异常值\n",
    "train = train[train['收率']>0.87]\n",
    "        \n",
    "train = train[good_cols]\n",
    "good_cols.remove('收率')\n",
    "test  = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 合并数据集\n",
    "target = train['收率']\n",
    "del train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return 7*3600/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (2*3600+30*60)/3600\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    \n",
    "    return tm\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    data[f] = data[f].apply(timeTranSecond)\n",
    "\n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    \n",
    "    return tm\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: getDuration(df[f]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_columns = [f for f in data.columns if f != '样本id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label encoder\n",
    "for f in cate_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造每个特征对于异常值的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain['target'] = target\\ntrain['outliers'] = 0\\ntrain.loc[train['target'] <= 0.87, 'outliers'] = 1\\ntrain['outliers'].value_counts()\\nfor f in cate_columns:\\n    colname = f+'_outliers_mean'\\n    order_label = train.groupby([f])['outliers'].mean()\\n    for df in [train, test]:\\n        df[colname] = df[f].map(order_label)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train['target'] = target\n",
    "train['outliers'] = 0\n",
    "train.loc[train['target'] <= 0.87, 'outliers'] = 1\n",
    "train['outliers'].value_counts()\n",
    "for f in cate_columns:\n",
    "    colname = f+'_outliers_mean'\n",
    "    order_label = train.groupby([f])['outliers'].mean()\n",
    "    for df in [train, test]:\n",
    "        df[colname] = df[f].map(order_label)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加新特征，将收率进行分箱，然后构造每个特征中的类别对应不同收率的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>样本id</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>B1</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B10</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B14</th>\n",
       "      <th>target</th>\n",
       "      <th>intTarget_0.0</th>\n",
       "      <th>intTarget_1.0</th>\n",
       "      <th>intTarget_2.0</th>\n",
       "      <th>intTarget_3.0</th>\n",
       "      <th>intTarget_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          样本id  A5  A6  A7  A8  A9  A10  A11  A12  A14  A15  A16  A17  A19  \\\n",
       "0  sample_1528   0   0   0   0   0    0    0    0    0    0    0    0    0   \n",
       "1  sample_1698   1   1   0   0   1    1    1    1    1    1    1    1    1   \n",
       "2   sample_639   1   1   0   0   1    2    1    1    1    1    1    1    1   \n",
       "3   sample_483   2   0   0   0   2    0    2    0    2    0    2    0    1   \n",
       "4   sample_617   3   1   0   0   3    1    3    1    3    1    3    1    1   \n",
       "\n",
       "   A20  A21  A22  A24  A25  A26  A27  A28  B1  B4  B5  B6  B7  B8  B9  B10  \\\n",
       "0    0    0    0    0    0    0    0    0   0   0   0   0   0   0   0    0   \n",
       "1    1    0    0    1    1    1    1    1   1   0   1   1   1   0   0    0   \n",
       "2    0    0    0    1    2    1    1    1   1   0   1   1   2   0   0    0   \n",
       "3    0    0    1    2    3    2    2    1   2   0   2   0   3   0   0    0   \n",
       "4    1    0    0    3    1    3    1    1   1   0   3   1   4   0   0    0   \n",
       "\n",
       "   B11  B12  B14  target  intTarget_0.0  intTarget_1.0  intTarget_2.0  \\\n",
       "0    0    0    0   0.879              1              0              0   \n",
       "1    1    1    0   0.902              0              1              0   \n",
       "2    1    1    0   0.936              0              0              1   \n",
       "3    0    0    0   0.902              0              1              0   \n",
       "4    1    1    1   0.983              0              0              0   \n",
       "\n",
       "   intTarget_3.0  intTarget_4.0  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f1 in cate_columns:\n",
    "    for f2 in li:\n",
    "        col_name = f1+\"_\"+f2+'_mean'\n",
    "        mean_features.append(col_name)\n",
    "        order_label = train.groupby([f1])[f2].mean()\n",
    "        for df in [train, test]:\n",
    "            df[col_name] = df[f].map(order_label)\n",
    "\n",
    "train.drop(li, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['样本id','target'], axis=1, inplace=True)\n",
    "test = test[train.columns]\n",
    "X_train = train.values\n",
    "y_train = target.values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000213649\tvalid_1's l2: 0.000238709\n",
      "[400]\ttraining's l2: 0.000165397\tvalid_1's l2: 0.000194135\n",
      "[600]\ttraining's l2: 0.00014877\tvalid_1's l2: 0.000186247\n",
      "[800]\ttraining's l2: 0.000139663\tvalid_1's l2: 0.000183224\n",
      "[1000]\ttraining's l2: 0.000134053\tvalid_1's l2: 0.00018144\n",
      "[1200]\ttraining's l2: 0.000129792\tvalid_1's l2: 0.000180621\n",
      "[1400]\ttraining's l2: 0.000126568\tvalid_1's l2: 0.000180056\n",
      "[1600]\ttraining's l2: 0.00012393\tvalid_1's l2: 0.000179733\n",
      "[1800]\ttraining's l2: 0.000121882\tvalid_1's l2: 0.000179494\n",
      "[2000]\ttraining's l2: 0.000119955\tvalid_1's l2: 0.000179393\n",
      "Early stopping, best iteration is:\n",
      "[2033]\ttraining's l2: 0.000119666\tvalid_1's l2: 0.000179346\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000212428\tvalid_1's l2: 0.000234753\n",
      "[400]\ttraining's l2: 0.000163155\tvalid_1's l2: 0.000208565\n",
      "[600]\ttraining's l2: 0.000146908\tvalid_1's l2: 0.000202205\n",
      "[800]\ttraining's l2: 0.000137427\tvalid_1's l2: 0.000199653\n",
      "[1000]\ttraining's l2: 0.000130877\tvalid_1's l2: 0.000198783\n",
      "[1200]\ttraining's l2: 0.000126115\tvalid_1's l2: 0.000198345\n",
      "Early stopping, best iteration is:\n",
      "[1268]\ttraining's l2: 0.000124671\tvalid_1's l2: 0.00019811\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000221315\tvalid_1's l2: 0.000269277\n",
      "[400]\ttraining's l2: 0.00017008\tvalid_1's l2: 0.000214002\n",
      "[600]\ttraining's l2: 0.000150317\tvalid_1's l2: 0.000201469\n",
      "[800]\ttraining's l2: 0.00014\tvalid_1's l2: 0.000197265\n",
      "[1000]\ttraining's l2: 0.000133664\tvalid_1's l2: 0.000195252\n",
      "[1200]\ttraining's l2: 0.000128945\tvalid_1's l2: 0.000194385\n",
      "[1400]\ttraining's l2: 0.000125436\tvalid_1's l2: 0.000193822\n",
      "Early stopping, best iteration is:\n",
      "[1420]\ttraining's l2: 0.000125086\tvalid_1's l2: 0.000193654\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000218265\tvalid_1's l2: 0.000230474\n",
      "[400]\ttraining's l2: 0.000169915\tvalid_1's l2: 0.000194255\n",
      "[600]\ttraining's l2: 0.000153751\tvalid_1's l2: 0.000184225\n",
      "[800]\ttraining's l2: 0.000144311\tvalid_1's l2: 0.000180462\n",
      "[1000]\ttraining's l2: 0.000138006\tvalid_1's l2: 0.000178546\n",
      "[1200]\ttraining's l2: 0.000133146\tvalid_1's l2: 0.000177046\n",
      "[1400]\ttraining's l2: 0.000129415\tvalid_1's l2: 0.000175694\n",
      "[1600]\ttraining's l2: 0.000126445\tvalid_1's l2: 0.000174757\n",
      "[1800]\ttraining's l2: 0.000124039\tvalid_1's l2: 0.000174598\n",
      "[2000]\ttraining's l2: 0.000121951\tvalid_1's l2: 0.000173753\n",
      "[2200]\ttraining's l2: 0.000120182\tvalid_1's l2: 0.000173001\n",
      "[2400]\ttraining's l2: 0.000118519\tvalid_1's l2: 0.000172642\n",
      "Early stopping, best iteration is:\n",
      "[2433]\ttraining's l2: 0.00011827\tvalid_1's l2: 0.000172588\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000217078\tvalid_1's l2: 0.000232025\n",
      "[400]\ttraining's l2: 0.000171866\tvalid_1's l2: 0.000190875\n",
      "[600]\ttraining's l2: 0.000154452\tvalid_1's l2: 0.00018165\n",
      "[800]\ttraining's l2: 0.00014482\tvalid_1's l2: 0.00017817\n",
      "[1000]\ttraining's l2: 0.000138852\tvalid_1's l2: 0.000175815\n",
      "[1200]\ttraining's l2: 0.000134389\tvalid_1's l2: 0.000174941\n",
      "[1400]\ttraining's l2: 0.000130941\tvalid_1's l2: 0.000173711\n",
      "[1600]\ttraining's l2: 0.000128246\tvalid_1's l2: 0.00017275\n",
      "[1800]\ttraining's l2: 0.000126163\tvalid_1's l2: 0.000172203\n",
      "[2000]\ttraining's l2: 0.000124293\tvalid_1's l2: 0.000171717\n",
      "[2200]\ttraining's l2: 0.000122573\tvalid_1's l2: 0.000171148\n",
      "[2400]\ttraining's l2: 0.000121122\tvalid_1's l2: 0.000170485\n",
      "[2600]\ttraining's l2: 0.000120062\tvalid_1's l2: 0.000170355\n",
      "Early stopping, best iteration is:\n",
      "[2556]\ttraining's l2: 0.000120117\tvalid_1's l2: 0.000170302\n",
      "CV score: 0.00018280\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.422932\tvalid_data-rmse:0.423818\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256987\tvalid_data-rmse:0.257703\n",
      "[200]\ttrain-rmse:0.156566\tvalid_data-rmse:0.157217\n",
      "[300]\ttrain-rmse:0.095961\tvalid_data-rmse:0.096496\n",
      "[400]\ttrain-rmse:0.059487\tvalid_data-rmse:0.059991\n",
      "[500]\ttrain-rmse:0.037744\tvalid_data-rmse:0.038446\n",
      "[600]\ttrain-rmse:0.024976\tvalid_data-rmse:0.026087\n",
      "[700]\ttrain-rmse:0.017557\tvalid_data-rmse:0.019294\n",
      "[800]\ttrain-rmse:0.013337\tvalid_data-rmse:0.015854\n",
      "[900]\ttrain-rmse:0.010958\tvalid_data-rmse:0.014198\n",
      "[1000]\ttrain-rmse:0.009588\tvalid_data-rmse:0.013447\n",
      "[1100]\ttrain-rmse:0.00878\tvalid_data-rmse:0.0131\n",
      "[1200]\ttrain-rmse:0.008221\tvalid_data-rmse:0.012923\n",
      "[1300]\ttrain-rmse:0.007836\tvalid_data-rmse:0.012845\n",
      "[1400]\ttrain-rmse:0.007532\tvalid_data-rmse:0.012809\n",
      "[1500]\ttrain-rmse:0.007282\tvalid_data-rmse:0.012808\n",
      "[1600]\ttrain-rmse:0.007082\tvalid_data-rmse:0.012818\n",
      "Stopping. Best iteration:\n",
      "[1464]\ttrain-rmse:0.007367\tvalid_data-rmse:0.0128\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.424042\tvalid_data-rmse:0.41936\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257681\tvalid_data-rmse:0.254183\n",
      "[200]\ttrain-rmse:0.157015\tvalid_data-rmse:0.154354\n",
      "[300]\ttrain-rmse:0.096198\tvalid_data-rmse:0.094031\n",
      "[400]\ttrain-rmse:0.059587\tvalid_data-rmse:0.057884\n",
      "[500]\ttrain-rmse:0.037741\tvalid_data-rmse:0.036538\n",
      "[600]\ttrain-rmse:0.024897\tvalid_data-rmse:0.024588\n",
      "[700]\ttrain-rmse:0.017385\tvalid_data-rmse:0.018449\n",
      "[800]\ttrain-rmse:0.013053\tvalid_data-rmse:0.015646\n",
      "[900]\ttrain-rmse:0.010588\tvalid_data-rmse:0.014519\n",
      "[1000]\ttrain-rmse:0.009178\tvalid_data-rmse:0.014118\n",
      "[1100]\ttrain-rmse:0.008334\tvalid_data-rmse:0.013998\n",
      "[1200]\ttrain-rmse:0.007768\tvalid_data-rmse:0.014004\n",
      "[1300]\ttrain-rmse:0.007381\tvalid_data-rmse:0.014027\n",
      "Stopping. Best iteration:\n",
      "[1136]\ttrain-rmse:0.008102\tvalid_data-rmse:0.013988\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.422401\tvalid_data-rmse:0.425951\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256663\tvalid_data-rmse:0.259811\n",
      "[200]\ttrain-rmse:0.1564\tvalid_data-rmse:0.159248\n",
      "[300]\ttrain-rmse:0.095813\tvalid_data-rmse:0.098512\n",
      "[400]\ttrain-rmse:0.059393\tvalid_data-rmse:0.061812\n",
      "[500]\ttrain-rmse:0.037681\tvalid_data-rmse:0.039764\n",
      "[600]\ttrain-rmse:0.024927\tvalid_data-rmse:0.026966\n",
      "[700]\ttrain-rmse:0.017514\tvalid_data-rmse:0.019982\n",
      "[800]\ttrain-rmse:0.013289\tvalid_data-rmse:0.016515\n",
      "[900]\ttrain-rmse:0.010909\tvalid_data-rmse:0.01494\n",
      "[1000]\ttrain-rmse:0.009524\tvalid_data-rmse:0.014267\n",
      "[1100]\ttrain-rmse:0.008702\tvalid_data-rmse:0.014025\n",
      "[1200]\ttrain-rmse:0.008158\tvalid_data-rmse:0.013939\n",
      "[1300]\ttrain-rmse:0.007771\tvalid_data-rmse:0.013946\n",
      "[1400]\ttrain-rmse:0.007447\tvalid_data-rmse:0.013991\n",
      "Stopping. Best iteration:\n",
      "[1233]\ttrain-rmse:0.008018\tvalid_data-rmse:0.013929\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.422949\tvalid_data-rmse:0.423759\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256994\tvalid_data-rmse:0.256879\n",
      "[200]\ttrain-rmse:0.156589\tvalid_data-rmse:0.155882\n",
      "[300]\ttrain-rmse:0.095942\tvalid_data-rmse:0.095027\n",
      "[400]\ttrain-rmse:0.059488\tvalid_data-rmse:0.058664\n",
      "[500]\ttrain-rmse:0.037722\tvalid_data-rmse:0.037268\n",
      "[600]\ttrain-rmse:0.024976\tvalid_data-rmse:0.025081\n",
      "[700]\ttrain-rmse:0.017577\tvalid_data-rmse:0.018497\n",
      "[800]\ttrain-rmse:0.013343\tvalid_data-rmse:0.015201\n",
      "[900]\ttrain-rmse:0.010932\tvalid_data-rmse:0.013675\n",
      "[1000]\ttrain-rmse:0.009514\tvalid_data-rmse:0.013019\n",
      "[1100]\ttrain-rmse:0.008652\tvalid_data-rmse:0.012743\n",
      "[1200]\ttrain-rmse:0.00808\tvalid_data-rmse:0.012629\n",
      "[1300]\ttrain-rmse:0.007672\tvalid_data-rmse:0.012588\n",
      "[1400]\ttrain-rmse:0.007354\tvalid_data-rmse:0.0126\n",
      "[1500]\ttrain-rmse:0.007112\tvalid_data-rmse:0.012631\n",
      "Stopping. Best iteration:\n",
      "[1308]\ttrain-rmse:0.007641\tvalid_data-rmse:0.012586\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.423228\tvalid_data-rmse:0.422634\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257182\tvalid_data-rmse:0.256865\n",
      "[200]\ttrain-rmse:0.156723\tvalid_data-rmse:0.156561\n",
      "[300]\ttrain-rmse:0.096012\tvalid_data-rmse:0.096002\n",
      "[400]\ttrain-rmse:0.059516\tvalid_data-rmse:0.059737\n",
      "[500]\ttrain-rmse:0.037763\tvalid_data-rmse:0.038299\n",
      "[600]\ttrain-rmse:0.024999\tvalid_data-rmse:0.026024\n",
      "[700]\ttrain-rmse:0.017615\tvalid_data-rmse:0.019308\n",
      "[800]\ttrain-rmse:0.013426\tvalid_data-rmse:0.015836\n",
      "[900]\ttrain-rmse:0.011079\tvalid_data-rmse:0.01411\n",
      "[1000]\ttrain-rmse:0.009738\tvalid_data-rmse:0.013308\n",
      "[1100]\ttrain-rmse:0.008919\tvalid_data-rmse:0.012961\n",
      "[1200]\ttrain-rmse:0.008372\tvalid_data-rmse:0.012795\n",
      "[1300]\ttrain-rmse:0.007988\tvalid_data-rmse:0.012737\n",
      "[1400]\ttrain-rmse:0.007678\tvalid_data-rmse:0.012726\n",
      "[1500]\ttrain-rmse:0.007435\tvalid_data-rmse:0.012756\n",
      "Stopping. Best iteration:\n",
      "[1378]\ttrain-rmse:0.00774\tvalid_data-rmse:0.012719\n",
      "\n",
      "CV score: 0.00017474\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'eta': 0.005, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001727489889676719"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将lgb和xgb的结果进行stacking\n",
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('datasets/jinnan/jinnan_round1_submit_20181227.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"datasets/jinnan/results.csv\", index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
